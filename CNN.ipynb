{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_numpy = np.loadtxt('./dataset/stock_2.csv', delimiter=\",\", dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['index_code', 'date', 'open', 'close', 'low', 'high', 'volume',\n",
       "        'money', 'change', 'label'],\n",
       "       ['sh000001', '1990/12/20', '104.3', '104.39', '99.98', '104.39',\n",
       "        '197000', '85000', '0.044108822', '109.13'],\n",
       "       ['sh000001', '1990/12/21', '109.07', '109.13', '103.73', '109.13',\n",
       "        '28000', '16100', '0.045406648', '114.55'],\n",
       "       ['sh000001', '1990/12/24', '113.57', '114.55', '109.13', '114.55',\n",
       "        '32000', '31100', '0.049665537', '120.25'],\n",
       "       ['sh000001', '1990/12/25', '120.09', '120.25', '114.55', '120.25',\n",
       "        '15000', '6500', '0.04975993', '125.27']], dtype='<U12')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_numpy[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'headd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-0098bde90a85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./dataset/stock_2.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheadd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda01\\envs\\WZQ\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'headd'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('./dataset/stock_2.csv',delimiter=',',dtype='str')\n",
    "dataset.headd(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用pandas 导入的数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6109 entries, 0 to 6108\n",
      "Data columns (total 10 columns):\n",
      "index_code    6109 non-null object\n",
      "date          6109 non-null object\n",
      "open          6109 non-null object\n",
      "close         6109 non-null object\n",
      "low           6109 non-null object\n",
      "high          6109 non-null object\n",
      "volume        6109 non-null object\n",
      "money         6109 non-null object\n",
      "change        6109 non-null object\n",
      "label         6109 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 477.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sh000001', '1990/12/20', '104.3', '104.39', '99.98', '104.39',\n",
       "        '197000', '85000', '0.044108822', '109.13'],\n",
       "       ['sh000001', '1990/12/21', '109.07', '109.13', '103.73', '109.13',\n",
       "        '28000', '16100', '0.045406648', '114.55'],\n",
       "       ['sh000001', '1990/12/24', '113.57', '114.55', '109.13', '114.55',\n",
       "        '32000', '31100', '0.049665537', '120.25'],\n",
       "       ['sh000001', '1990/12/25', '120.09', '120.25', '114.55', '120.25',\n",
       "        '15000', '6500', '0.04975993', '125.27'],\n",
       "       ['sh000001', '1990/12/26', '125.27', '125.27', '120.25', '125.27',\n",
       "        '100000', '53700', '0.041746362', '125.28']], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas 转 numpy ,网络只能输入矩阵，不能输入pandas的数据类型\n",
    "dataset_np = dataset.values\n",
    "dataset_np[:5, :] #查看前面5行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉前面两个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array = dataset_np[:, 2:] #去掉前面两列\n",
    "dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['104.3', '104.39', '99.98', '104.39', '197000', '85000',\n",
       "        '0.044108822', '109.13'],\n",
       "       ['109.07', '109.13', '103.73', '109.13', '28000', '16100',\n",
       "        '0.045406648', '114.55'],\n",
       "       ['113.57', '114.55', '109.13', '114.55', '32000', '31100',\n",
       "        '0.049665537', '120.25'],\n",
       "       ['120.09', '120.25', '114.55', '120.25', '15000', '6500',\n",
       "        '0.04975993', '125.27'],\n",
       "       ['125.27', '125.27', '120.25', '125.27', '100000', '53700',\n",
       "        '0.041746362', '125.28']], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将object类型强转为float32类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_array = dataset_array.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0430000e+02, 1.0439000e+02, 9.9980003e+01, 1.0439000e+02,\n",
       "        1.9700000e+05, 8.5000000e+04, 4.4108823e-02, 1.0913000e+02],\n",
       "       [1.0907000e+02, 1.0913000e+02, 1.0373000e+02, 1.0913000e+02,\n",
       "        2.8000000e+04, 1.6100000e+04, 4.5406647e-02, 1.1455000e+02],\n",
       "       [1.1357000e+02, 1.1455000e+02, 1.0913000e+02, 1.1455000e+02,\n",
       "        3.2000000e+04, 3.1100000e+04, 4.9665537e-02, 1.2025000e+02],\n",
       "       [1.2009000e+02, 1.2025000e+02, 1.1455000e+02, 1.2025000e+02,\n",
       "        1.5000000e+04, 6.5000000e+03, 4.9759932e-02, 1.2527000e+02],\n",
       "       [1.2527000e+02, 1.2527000e+02, 1.2025000e+02, 1.2527000e+02,\n",
       "        1.0000000e+05, 5.3700000e+04, 4.1746363e-02, 1.2528000e+02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把x 和 y 给切出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset_array[:, :-1]\n",
    "y = dataset_array[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,y_train,X_test,y_test= train_test_split(X,y,test_size=0.2,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard = StandardScaler()\n",
    "standard.fit(X_train)\n",
    "\n",
    "X_train_standard = standard.transform(X_train)\n",
    "X_test_standard = standard.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4887, 7)\n",
      "(4887, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_standard.shape)\n",
    "print(X_test_standard.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #input[-1,7]\n",
    "        self.hidden1 = nn.Linear(7,64)#64个神经元 [-1,7]*[7,64]=[-1,64]\n",
    "        self.hidden2 = nn.Linear(64,32)#[-1,64]*[64,32]=[-1,32]\n",
    "        self.hidden3 = nn.Linear(32,10)#[-1,32]*[]\n",
    "        \n",
    "        #output\n",
    "        self.pred = nn.Linear(10,1)#[-1,10]*[10,1]=[-1,1]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        out = self.pred(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden1): Linear(in_features=7, out_features=64, bias=True)\n",
       "  (hidden2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (hidden3): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (pred): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden1): Linear(in_features=7, out_features=64, bias=True)\n",
       "  (hidden2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (hidden3): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (pred): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "loss_function = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    #将array to tensor\n",
    "    input_x = Variable(torch.FloatTensor(X_train_standard))\n",
    "    input_y = Variable(torch.FloatTensor(y_train))\n",
    "    \n",
    "    y_predit= net(input_x) #将输入数据 扔进 神经网络 去预测出一个值\n",
    "    loss = loss_function(input_y,y_predit) #计算MSE\n",
    "    optimizer.zero_gard() #梯度归零\n",
    "    loss.backward() #反向传播，梯度下降\n",
    "    optimizer.step() #找到新的梯度\n",
    "    \n",
    "    print('EPOCH:',epoch , \"loss:\",loss.data)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:WZQ]",
   "language": "python",
   "name": "conda-env-WZQ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
